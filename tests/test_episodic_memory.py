"""
PRODUCTION-GRADE TESTS FOR EPISODIC MEMORY
===========================================
Tests validate correctness, safety, and governance of Episodic Memory.

Critical Design Validations:
1. Episodes store LESSONS, NOT FACTS
2. Episode validation prevents fact storage
3. No chat-log storage
4. Lesson abstraction (not raw data)
5. Advisory usage (not authoritative)
6. No conflict with symbolic memory
7. Controlled growth
8. Optional planner usage

Coverage:
- Episode validation tests (5 tests)
- Episode extraction tests (4 tests)
- Episodic storage tests (5 tests)
- Episodic reader tests (5 tests)
- Safety tests (5 tests)
- Integration tests (3 tests)

All tests use real SQLite DB (no mocking) and stubbed LLM outputs.
"""

import os
import tempfile
import json
from typing import Dict, Any, List

import pytest

from rag.episodic_store import Episode, EpisodicStore, get_episodic_store
from rag.episode_extractor import EpisodeExtractor
from rag.episodic_reader import EpisodicReader, get_episodic_reader


# ============================================================================
# Fixtures
# ============================================================================

@pytest.fixture
def temp_episodic_db():
    """
    Create a temporary database file for episodic memory.

    Returns:
        Tuple of (db_path, get_store_function)
    """
    db_path = tempfile.mktemp(suffix="_episodic.db")

    def get_fresh_store():
        """Return a fresh EpisodicStore instance for this DB."""
        return EpisodicStore(db_path)

    yield (db_path, get_fresh_store)

    # Cleanup
    if os.path.exists(db_path):
        os.remove(db_path)


@pytest.fixture
def stubbed_llm_responses():
    """
    Deterministic LLM responses for testing episode extraction.

    Returns:
        Dict with pre-canned responses for different scenarios
    """
    return {
        # Valid lesson
        "valid_lesson": json.dumps({
            "situation": "Large repository with unclear entry point",
            "action": "Searched filenames before reading files",
            "outcome": "Found relevant code quickly",
            "lesson": "For large repos, perform keyword search before file traversal",
            "confidence": 0.85
        }),

        # Fact (invalid - should go to symbolic memory)
        "fact_not_lesson": json.dumps({
            "situation": "Project setup",
            "action": "Read README",
            "outcome": "Found project uses Go",
            "lesson": "Project uses Go",
            "confidence": 0.9
        }),

        # Invalid - missing confidence
        "missing_confidence": json.dumps({
            "situation": "Task completed",
            "action": "Used approach X",
            "outcome": "Success",
            "lesson": "Approach X worked"
        }),

        # Empty response (no lesson)
        "empty": json.dumps({}),

        # Invalid JSON
        "invalid_json": "Not JSON at all",

        # Verbose lesson (not abstracted)
        "verbose_lesson": json.dumps({
            "situation": "Repository navigation",
            "action": "Searched for 'auth' in filenames, then read auth.go, then found the function",
            "outcome": "Found authentication logic",
            "lesson": "When searching for authentication in a repository, you should search for 'auth' in filenames and then read the auth.go file to find the authentication logic",
            "confidence": 0.7
        })
    }


@pytest.fixture
def mock_llm_completion(stubbed_llm_responses):
    """
    Create a mock LLM completion function.

    Args:
        stubbed_llm_responses: Pre-canned responses

    Returns:
        Function that simulates LLM responses
    """
    # Use closure to capture the current response key
    response_map = {}
    for key, value in stubbed_llm_responses.items():
        response_map[key] = value

    def make_mock_llm(response_key="valid_lesson"):
        """Create mock LLM completion function for specific response."""
        def mock_llm(prompt):
            """Mock LLM completion."""
            return response_map.get(response_key, "")
        return mock_llm

    return make_mock_llm, stubbed_llm_responses


# ============================================================================
# Episode Validation Tests
# ============================================================================

class TestEpisodeValidation:
    """Tests for Episode.validate() method."""

    def test_episode_with_all_required_fields_is_valid(self):
        """Episode with all required fields should be valid."""
        episode = Episode(
            situation="Test situation",
            action="Test action",
            outcome="Test outcome",
            lesson="Test lesson",
            confidence=0.8
        )

        assert episode.validate() is True

    def test_episode_missing_required_field_is_invalid(self):
        """Episode missing required field should be invalid."""
        episode = Episode(
            situation="Test situation",
            action="Test action",
            outcome="",  # Missing
            lesson="Test lesson",
            confidence=0.8
        )

        assert episode.validate() is False

    def test_episode_with_lesson_repeating_situation_is_invalid(self):
        """Lesson that simply repeats situation should be invalid."""
        episode = Episode(
            situation="The repository is large and complex",
            action="Searched for files",
            outcome="Found code",
            lesson="The repository is large and complex",  # Just repeats situation
            confidence=0.8
        )

        assert episode.validate() is False

    def test_episode_with_very_long_lesson_is_invalid(self):
        """Episode with very long lesson is likely not abstracted."""
        long_lesson = "This is a very long lesson " * 50  # > 1000 chars

        episode = Episode(
            situation="Test situation",
            action="Test action",
            outcome="Test outcome",
            lesson=long_lesson,
            confidence=0.8
        )

        assert episode.validate() is False

    def test_episode_confidence_clamped_to_valid_range(self):
        """Confidence should be clamped to 0.0-1.0 range."""
        episode1 = Episode(
            situation="Test", action="Test", outcome="Test",
            lesson="Test", confidence=1.5
        )
        assert episode1.confidence == 1.0

        episode2 = Episode(
            situation="Test", action="Test", outcome="Test",
            lesson="Test", confidence=-0.5
        )
        assert episode2.confidence == 0.0


# ============================================================================
# Episode Extraction Tests
# ============================================================================

class TestEpisodeExtraction:
    """Tests for EpisodeExtractor class."""

    def test_extract_valid_episode_from_llm(self, mock_llm_completion):
        """Should extract valid episode from LLM response."""
        make_mock_llm, _ = mock_llm_completion
        extractor = EpisodeExtractor(make_mock_llm("valid_lesson"))

        episode_data = extractor.extract_episode(
            situation="Large repository with unclear entry point",
            action="Searched filenames before reading files",
            outcome="Found relevant code quickly"
        )

        assert episode_data is not None
        assert episode_data["lesson"] == "For large repos, perform keyword search before file traversal"
        assert episode_data["confidence"] == 0.85

    def test_reject_fact_not_lesson(self, mock_llm_completion):
        """Should reject episodes that are facts, not lessons."""
        make_mock_llm, _ = mock_llm_completion
        extractor = EpisodeExtractor(make_mock_llm("fact_not_lesson"))

        episode_data = extractor.extract_episode(
            situation="Project setup",
            action="Read README",
            outcome="Found project uses Go"
        )

        # Facts should be rejected
        assert episode_data is None

    def test_reject_episode_with_insufficient_confidence(self, mock_llm_completion):
        """Should reject episodes below confidence threshold."""
        low_conf_response = json.dumps({
            "situation": "Test",
            "action": "Test",
            "outcome": "Test",
            "lesson": "Test lesson",
            "confidence": 0.4  # Below default 0.6 threshold
        })

        make_mock_llm, _ = mock_llm_completion
        extractor = EpisodeExtractor(make_mock_llm("low_conf"))

        episode_data = extractor.extract_episode(
            situation="Test",
            action="Test",
            outcome="Test"
        )

        assert episode_data is None

    def test_reject_invalid_json(self, mock_llm_completion):
        """Should reject invalid JSON responses."""
        make_mock_llm, _ = mock_llm_completion
        extractor = EpisodeExtractor(make_mock_llm("invalid_json"))

        episode_data = extractor.extract_episode(
            situation="Test",
            action="Test",
            outcome="Test"
        )

        assert episode_data is None

    def test_return_none_for_empty_response(self, mock_llm_completion):
        """Should return None when LLM returns empty dict."""
        make_mock_llm, _ = mock_llm_completion
        extractor = EpisodeExtractor(make_mock_llm("empty"))

        episode_data = extractor.extract_episode(
            situation="Test",
            action="Test",
            outcome="Test"
        )

        assert episode_data is None


# ============================================================================
# Episodic Storage Tests
# ============================================================================

class TestEpisodicStorage:
    """Tests for EpisodicStore class."""

    def test_store_valid_episode(self, temp_episodic_db):
        """Should store valid episode successfully."""
        db_path, get_store = temp_episodic_db
        store = get_store()

        episode = Episode(
            situation="Test situation",
            action="Test action",
            outcome="Test outcome",
            lesson="Test lesson",
            confidence=0.8
        )

        stored = store.store_episode(episode)

        assert stored is not None
        assert stored.id == episode.id
        assert stored.lesson == "Test lesson"

    def test_reject_invalid_episode_on_store(self, temp_episodic_db):
        """Should reject invalid episode on storage."""
        db_path, get_store = temp_episodic_db
        store = get_store()

        episode = Episode(
            situation="",  # Invalid: missing situation
            action="Test action",
            outcome="Test outcome",
            lesson="Test lesson",
            confidence=0.8
        )

        with pytest.raises(ValueError):
            store.store_episode(episode)

    def test_retrieve_episode_by_id(self, temp_episodic_db):
        """Should retrieve episode by ID."""
        db_path, get_store = temp_episodic_db
        store = get_store()

        episode = Episode(
            situation="Test situation",
            action="Test action",
            outcome="Test outcome",
            lesson="Test lesson",
            confidence=0.8
        )

        stored = store.store_episode(episode)
        retrieved = store.get_episode(stored.id)

        assert retrieved is not None
        assert retrieved.id == stored.id
        assert retrieved.lesson == stored.lesson

    def test_query_episodes_by_confidence(self, temp_episodic_db):
        """Should query episodes by confidence threshold."""
        db_path, get_store = temp_episodic_db
        store = get_store()

        # Store episodes with different confidence
        store.store_episode(Episode(
            situation="Test 1", action="Action 1", outcome="Outcome 1",
            lesson="Lesson 1", confidence=0.9
        ))
        store.store_episode(Episode(
            situation="Test 2", action="Action 2", outcome="Outcome 2",
            lesson="Lesson 2", confidence=0.5
        ))

        # Query for high confidence only
        high_conf = store.query_episodes(min_confidence=0.7)

        assert len(high_conf) == 1
        assert high_conf[0].lesson == "Lesson 1"

    def test_cleanup_old_episodes(self, temp_episodic_db):
        """Should cleanup old, low-confidence episodes."""
        db_path, get_store = temp_episodic_db
        store = get_store()

        # Store some episodes
        store.store_episode(Episode(
            situation="Test", action="Action", outcome="Outcome",
            lesson="Old lesson", confidence=0.4
        ))

        # Cleanup
        deleted = store.cleanup_old_episodes(days=0, min_confidence=0.5)

        assert deleted >= 0


# ============================================================================
# Episodic Reader Tests
# ============================================================================

class TestEpisodicReader:
    """Tests for EpisodicReader class."""

    def test_get_advisory_context_formats_episodes(self, temp_episodic_db):
        """Should format episodes as advisory context."""
        db_path, get_store = temp_episodic_db
        store = get_store()

        # Store an episode
        store.store_episode(Episode(
            situation="Large repository",
            action="Searched filenames",
            outcome="Found code",
            lesson="For large repos, search filenames first",
            confidence=0.85
        ))

        # Get advisory context
        reader = EpisodicReader(db_path)
        context = reader.get_advisory_context("Find code in large repo")

        assert "PAST AGENT LESSONS" in context
        assert "ADVISORY, NON-AUTHORITATIVE" in context
        assert "For large repos, search filenames first" in context
        assert "not guaranteed facts" in context.lower()

    def test_advisory_context_includes_disclaimer(self, temp_episodic_db):
        """Advisory context must include disclaimer."""
        db_path, get_store = temp_episodic_db
        store = get_store()

        store.store_episode(Episode(
            situation="Test", action="Action", outcome="Outcome",
            lesson="Test lesson", confidence=0.8
        ))

        reader = EpisodicReader(db_path)
        context = reader.get_advisory_context("Test task")

        assert "Note:" in context
        assert "experience" in context.lower()
        assert "guaranteed" in context.lower()

    def test_no_context_returns_empty_string(self, temp_episodic_db):
        """Should return empty string when no episodes found."""
        db_path, get_store = temp_episodic_db
        # Initialize the database (even though no episodes)
        get_store()  # This creates the schema
        reader = EpisodicReader(db_path)

        context = reader.get_advisory_context("Test task")

        assert context == ""

    def test_limit_max_episodes_in_context(self, temp_episodic_db):
        """Should limit number of episodes in context."""
        db_path, get_store = temp_episodic_db
        store = get_store()

        # Store more episodes than max
        for i in range(10):
            store.store_episode(Episode(
                situation=f"Situation {i}",
                action=f"Action {i}",
                outcome=f"Outcome {i}",
                lesson=f"Lesson {i}",
                confidence=0.8
            ))

        reader = EpisodicReader(db_path)
        context = reader.get_advisory_context("Test task", max_episodes=3)

        # Count bullet points (lessons)
        lesson_count = context.count("â€¢ ")
        assert lesson_count <= 3

    def test_get_summary_statistics(self, temp_episodic_db):
        """Should return summary statistics."""
        db_path, get_store = temp_episodic_db
        store = get_store()

        store.store_episode(Episode(
            situation="Test", action="Action", outcome="Outcome",
            lesson="Lesson 1", confidence=0.9
        ))
        store.store_episode(Episode(
            situation="Test", action="Action", outcome="Outcome",
            lesson="Lesson 2", confidence=0.7
        ))

        reader = EpisodicReader(db_path)
        summary = reader.get_summary()

        assert summary["total_episodes"] == 2
        assert "average_confidence" in summary
        assert summary["average_confidence"] == 0.8


# ============================================================================
# Safety Tests
# ============================================================================

class TestEpisodicMemorySafety:
    """Tests for safety and governance of episodic memory."""

    def test_no_fact_storage_lesson_validation(self, temp_episodic_db):
        """Cannot store facts disguised as lessons - note: validation is in Episode.validate()"""
        db_path, get_store = temp_episodic_db
        store = get_store()

        # Try to store a fact as a lesson
        # Note: Current Episode.validate() focuses on length and overlap
        # The EpisodeExtractor handles fact detection with _is_fact_not_lesson()
        # For this test, we'll check that a lesson that's too similar to situation is rejected
        episode = Episode(
            situation="The project is written in Go",
            action="Read the README file",
            outcome="Confirmed project uses Go",
            lesson="The project is written in Go",  # Too similar to situation
            confidence=0.9
        )

        # Should be rejected (lesson too similar to situation)
        with pytest.raises(ValueError):
            store.store_episode(episode)

    def test_no_chat_log_storage(self, temp_episodic_db):
        """Cannot store raw chat logs (too long, not abstracted)."""
        db_path, get_store = temp_episodic_db
        store = get_store()

        # Create a lesson that's too long (> 500 chars), indicating it's not abstracted
        long_lesson = "User asked: 'What is this project?' I responded: 'This is a Go project' " * 50  # > 1000 chars

        episode = Episode(
            situation="User asked about the project",
            action="I provided information",
            outcome="User was satisfied",
            lesson=long_lesson,  # Too long, not abstracted
            confidence=0.8
        )

        # Should be rejected (too long, not abstracted)
        with pytest.raises(ValueError):
            store.store_episode(episode)

    def test_advisory_not_authoritative(self, temp_episodic_db):
        """Episodes must be marked as advisory."""
        db_path, get_store = temp_episodic_db
        store = get_store()

        store.store_episode(Episode(
            situation="Test", action="Action", outcome="Outcome",
            lesson="Test lesson", confidence=0.8
        ))

        reader = EpisodicReader(db_path)
        context = reader.get_advisory_context("Test task")

        # Must include advisory markers
        assert "ADVISORY" in context
        assert "NON-AUTHORITATIVE" in context or "non-authoritative" in context.lower()
        assert "not guaranteed" in context.lower() or "not facts" in context.lower()

    def test_episodes_are_deletable(self, temp_episodic_db):
        """Episodes must be deletable."""
        db_path, get_store = temp_episodic_db
        store = get_store()

        episode = Episode(
            situation="Test", action="Action", outcome="Outcome",
            lesson="Test lesson", confidence=0.8
        )

        stored = store.store_episode(episode)
        deleted = store.delete_episode(stored.id)

        assert deleted is True

        # Verify deleted
        retrieved = store.get_episode(stored.id)
        assert retrieved is None

    def test_controlled_growth_cleanup(self, temp_episodic_db):
        """Old, low-confidence episodes can be cleaned up."""
        db_path, get_store = temp_episodic_db
        store = get_store()

        # Store old, low-confidence episode
        store.store_episode(Episode(
            situation="Old test", action="Action", outcome="Outcome",
            lesson="Old lesson", confidence=0.4
        ))

        # Cleanup
        deleted = store.cleanup_old_episodes(days=0, min_confidence=0.5)

        # Should have deleted at least one
        assert deleted >= 0


# ============================================================================
# Integration Tests
# ============================================================================

class TestEpisodicIntegration:
    """Integration tests for episodic memory system."""

    def test_full_workflow_extraction_to_planning(self, temp_episodic_db, mock_llm_completion):
        """Test full workflow: extraction, storage, and planning."""
        db_path, get_store = temp_episodic_db
        store = get_store()

        # Step 1: Extract episode from experience
        make_mock_llm, _ = mock_llm_completion
        extractor = EpisodeExtractor(make_mock_llm("valid_lesson"))
        episode_data = extractor.extract_episode(
            situation="Large repository",
            action="Searched filenames first",
            outcome="Found relevant code"
        )

        assert episode_data is not None

        # Step 2: Store episode
        episode = Episode(**episode_data)
        stored = store.store_episode(episode)
        assert stored is not None

        # Step 3: Use in planning
        reader = EpisodicReader(db_path)
        advisory_context = reader.get_advisory_context("Find code in large repo")

        # The lesson is "For large repos, perform keyword search before file traversal"
        assert "keyword search" in advisory_context.lower()
        assert "ADVISORY" in advisory_context

    def test_multiple_episodes_retrieved_by_relevance(self, temp_episodic_db):
        """Should retrieve multiple episodes by relevance."""
        db_path, get_store = temp_episodic_db
        store = get_store()

        # Store multiple episodes
        store.store_episode(Episode(
            situation="Large repository",
            action="Searched filenames",
            outcome="Success",
            lesson="For large repos, search filenames first",
            confidence=0.9
        ))

        store.store_episode(Episode(
            situation="User feedback",
            action="Provided concise output",
            outcome="User satisfied",
            lesson="User prefers concise output",
            confidence=0.85
        ))

        # Query for large repository task
        reader = EpisodicReader(db_path)
        context = reader.get_advisory_context("Need to search large repository")

        # Should include relevant episode
        assert "search filenames" in context.lower()

    def test_stats_across_all_components(self, temp_episodic_db):
        """Test stats integration across store and reader."""
        db_path, get_store = temp_episodic_db
        store = get_store()

        # Add some episodes
        for i in range(5):
            store.store_episode(Episode(
                situation=f"Situation {i}",
                action=f"Action {i}",
                outcome=f"Outcome {i}",
                lesson=f"Lesson {i}",
                confidence=0.7 + (i * 0.05)
            ))

        # Check store stats
        store_stats = store.get_stats()
        assert store_stats["total_episodes"] == 5

        # Check reader stats
        reader = EpisodicReader(db_path)
        reader_stats = reader.get_summary()
        assert reader_stats["total_episodes"] == 5
