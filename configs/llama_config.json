{
  "model_path": "",
  "port": 8000,
  "host": "0.0.0.0",
  "context_size": 32768,
  "n_gpu_layers": 99,
  "log_format": "text",
  "llama_server_bin": "~/llama.cpp/build/bin/llama-server",
  "comment": "Set model_path to your GGUF model file path"
}
