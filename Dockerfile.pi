# ========================================
# Build stage - compile llama-cpp-python with ARM optimizations
# Optimized for Raspberry Pi 5 (ARM64 Cortex-A76)
# ========================================
FROM python:3.11-slim as builder

# Install build dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    cmake \
    gcc \
    g++ \
    git \
    wget \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements first for better caching
COPY requirements.txt /tmp/requirements.txt

# Install Python dependencies (without llama-cpp-python for now)
RUN pip install --user --no-cache-dir \
    fastapi>=0.115.0 \
    uvicorn[standard]>=0.30.0 \
    pydantic>=2.0.0 \
    chromadb>=0.5.0 \
    httpx>=0.27.0 \
    aiohttp>=3.9.0 \
    python-dotenv>=1.0.0 \
    numpy>=1.24.0

# ========================================
# Runtime stage - minimal final image
# ========================================
FROM python:3.11-slim

# Install runtime dependencies only
RUN apt-get update && apt-get install -y \
    curl \
    libgomp1 \
    && rm -rf /var/lib/apt/lists/*

# Create non-root user for security
RUN groupadd -r pireader && useradd -r -g pireader pireader

# Create directories with proper ownership
RUN mkdir -p /app /app/data /app/models /app/configs && \
    chown -R pireader:pireader /app

# Switch to non-root user
USER pireader

# Copy virtual environment and site-packages from builder
COPY --from=builder /root/.local /home/pireader/.local

# Copy application code
COPY --chown=pireader:pireader . /app/
WORKDIR /app

# Update PATH to include user-local bin
ENV PATH=/home/pireader/.local/bin:$PATH
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1

# Install llama-cpp-python with ARM NEON optimizations
# These flags optimize for ARM64 architecture on Raspberry Pi 4/5
# Done at runtime stage to ensure proper ARM detection
RUN CMAKE_ARGS="-DLLAMA_NATIVE=ON -DLLAMA_ARM_NEON=ON -DLLAMA_ARM_FMA=ON \
                -DLLAMA_AVX=OFF -DLLAMA_AVX2=OFF -DLLAMA_F16C=OFF \
                -DLLAMA_FMA=OFF -DLLAMA_AVX512=OFF" \
    pip install --no-cache-dir --user llama-cpp-python>=0.3.0

# Create data directories structure
RUN mkdir -p /app/data/{docs,rag_index,logs} && \
    mkdir -p /app/models

# Expose API port
EXPOSE 8001

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8001/health || exit 1

# Run the API server with single worker for Pi resources
CMD ["python", "-m", "uvicorn", "api.main:app", \
     "--host", "0.0.0.0", \
     "--port", "8001", \
     "--workers", "1", \
     "--log-level", "info"]
